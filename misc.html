<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Menghan Xia</title>
	<link rel="shortcut icon" href="./assets/favicon.ico"/>
	<meta name="viewport" content="width=1000">
	<link rel="stylesheet" href="./assets/style.css">
	<script src="https://kit.fontawesome.com/9d357d053b.js" crossorigin="anonymous"></script>
</head>


<body id="body">
	<div id="main">
		<!-- #MENU -->
		<header id="header">		
			<!--<i class="fa-solid fa-bell fa-shake"></i>-->
			<a href="index.html"></i>HOME</a>&nbsp;&nbsp;|&nbsp;&nbsp;
			<a href="index.html#research">PUBLICATION</a>&nbsp;&nbsp;|&nbsp;&nbsp;
			<a href="misc.html">MISC</a>&nbsp;&nbsp;|&nbsp;&nbsp;
			<a href="https://clustrmaps.com/site/xda5"><i class="fa-solid fa-earth-asia fa-spin"></i></a>
		</header>
		<br><br>


		<br><br><br>
		<!--section 1 ======================================================================= -->
		<h1><font face="Comic sans MS"><b>Public Dataset</b>
		</font></h1><hr>
		<div id="dataset" class="section" style= "overflow-y:scroll;height:600px;">
		
			<!--topic 1-->
			<h3>Single Images</h3>
			<ul class="news-item">
				<li><a href="https://r0k.us/graphics/kodak/">Kodak Lossless True Color Image Suite</a> <br>
				<p style="line-height:120%">A classic lossless 24-bits per pixel image dataset, which is commonly used in image processing researches.</p>
				</li>
				
				<li><a href="http://hdrplusdata.org/dataset.html">HDR+ Burst Photography Dataset</a> <br>
				<p style="line-height:120%">No remarks.</p>
				</li>
				
				<li>History black & white images: <a href="https://www.boredpanda.com/historic-pictures-colorized/?utm_source=google&utm_medium=organic&utm_campaign=organic">Part I</a>, <a href="https://www.boredpanda.com/colorized-history-black-and-white-pictures-restored-in-color/?utm_source=google&utm_medium=organic&utm_campaign=organic">Part II</a>, <a href="https://www.boredpanda.com/colorized-historic-monochrome-photos/?utm_source=google&utm_medium=organic&utm_campaign=organic">Part III</a> <br>
				<p style="line-height:120%">Old black & white photos and their colorized variants by artists.</p>
				</li>
				
				<li><a href="https://r0k.us/graphics/kodak/">TELEDYNE FLIR Thermal Dataset</a> <br>
				<p style="line-height:120%">9,711 thermal and 9,233 RGB training/validation images with a suggested training/validation split. Besides, bounding box annotations across 15 different object categories are available.
				</li>
			</ul>

			<!--topic 2-->
			<h3>Stereo Images</h3>
			<ul class="news-item">
				<li><a href="https://yingqianwang.github.io/Flickr1024/">Flickr1024: A Large-Scale Dataset for Stereo Image Super-Resolution</a> <br>
				<p style="line-height:120%">1024 high-quality image pairs and covers diverse senarios.</p>
				</li>
				<li><a href="https://keystonedepth.cs.washington.edu/download">KeystoneDepth</a> <br>
				<p style="line-height:120%">A collection of 37,239 rectified historical stereo black & white image pairs from the Keystone-Mast Collection.</p>
				</li>
    
			</ul>
 
			<!--topic 3-->
			<h3>Light Fields</h3>
			<ul class="news-item">
				<li><a href="http://lightfields.stanford.edu/LF2016.html">Stanford Lytro Light Field Archive</a> <br>
				<p style="line-height:120%">A dataset captured by the Lytro Illum camera, which are organized into various categories.</p>
				</li>
				<li><a href="http://lightfield.stanford.edu/lfs.html">The (New) Stanford Light Field Archive</a> <br>
				<p style="line-height:120%">Several classic large-baseline light fields, captured by gantry.</p>
				</li>
				<li><a href="https://cseweb.ucsd.edu//~viscomp/projects/LF/papers/SIGASIA16/">A dataset provided by Kalantari et. al.</a> <br>
				<p style="line-height:120%">The training set contains 72 light fields while the testing set contains 30 light fields, which have some overlap with the <i>Stanford Lytro Light Field Archives</i>.</p>
				</li>
				<li><a href="https://hazirbas.com/datasets/ddff12scene/">DDFF 12-Scene Benchmark</a> <br>
				<p style="line-height:120%">DDFF 12-Scene dataset consists of 720 lightfield images and coregistered depth maps.</p>
				</li>
				<li><a href="https://www.irisa.fr/temics/demos/lightField/LowRank2/datasets/datasets.html">INRIA Light Field Dataset</a> <br>
				<p style="line-height:120%">63 light field captured by Lytro first generation camera, and 46 light fields captured by Lytro Illum camera.</p>
				</li>
				<li><a href="https://github.com/lightfield-analysis/resources">Light Field Resources</a> <br>
				<p style="line-height:120%">A repo for collecting links to data sets, source code, and other resources related to research on light fields for computer vision.</p>
				</li>
			</ul>
	
			<!--topic 4-->
			<h3>Talking Head Videos</h3>
			<ul class="news-item">
				<li><a href="https://celebv-hq.github.io/">CelebV-HQ</a> <br>
				<p style="line-height:120%">CelebV-HQ contains 35,666 video clips involving 15,653 identities and 83 manually labeled facial attributes covering appearance, action, and emotion.</p>
				</li>
				<li><a href="https://liangbinxie.github.io/projects/vfhq">VFHQ</a> <br>
				<p style="line-height:120%">As a new benchmark for video face super-resolution, VFHQ contains over 16,000 high-fidelity clips of diverse interview scenarios.</p>
				</li>
		
			</ul>
	
			<!--topic 5-->
			<h3>Others</h3>
			<ul class="news-item">
				<li><a href="https://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm#collect">CVonline: Image Databases</a> <br>
				<p style="line-height:120%">A collated list of image and video databases that people have found useful for computer vision research.</p>
				</li>
		
			</ul>
		</div>


		<br><br><br>
		<!--section 2 ======================================================================= -->
		<h1><font face="Comic sans MS"><b>Technics Memo</b>
		</font></h1><hr>
		<div id="technic" class="section" style= "overflow-y:scroll;height:600px;">
		
			<!--topic 1-->
			<h3>Differentiable Quantization</h3>
			<ul class="news-item">
				<li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9010945">
				"Differentiable Soft Quantization:Bridging Full-Precision and Low-Bit Neural Networks"</a>, ICCV 2019. <br>
				<p style="line-height:120%">No remarks.</p>
				</li>
				<li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8578437">
				"Learning Convolutional Networks for Content-weighted Image Compression"</a>, CVPR 2018. <br>
				<p style="line-height:120%">No remarks.</p>
				</li>
				<li><a href="https://machine-learning-and-security.github.io/papers/mlsec17_paper_54.pdf">
				"JPEG-resistant Adversarial Images"</a>, NIPS Workshops 2017. <br>
				<p style="line-height:120%">No remarks.</p>
				</li>
				<li><a href="https://eccv2018.org/openaccess/content_ECCV_2018/papers/Jiren_Zhu_HiDDeN_Hiding_Data_ECCV_2018_paper.pdf">
				"HiDDeN: Hiding Data With Deep Networks"</a>, ECCV 2018. <br>
				<p style="line-height:120%">No remarks.</p>
				</li>
			</ul>
	
			<!--topic 2-->
			<h3>Differentiable L0 Norm Regularity</h3>
			<ul class="news-item">
				<li><a href="https://openreview.net/pdf?id=H1Y8hhg0b">
					"Learning Sparse Neural Networks through L0 Regularization"</a>, ICLR 2018. <br>
					<p style="line-height:120%">No remarks.</p>
				</li>
				<li><a href="http://www.stats.ox.ac.uk/~cmaddis/pubs/concrete.pdf">
					"The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables"</a>, ICLR 2017. <br>
					<p style="line-height:120%">No remarks.</p>
				</li>
			
			</ul>
			
			<!--topic 3-->
			<h3>Soft Argmax</h3>
			<ul class="news-item">
				<li><a href="https://link.springer.com/content/pdf/10.1007/s10791-009-9110-3.pdf">
					"Gradient descent optimization of smoothed information retrieval metrics"</a>, Information Retrieval 2010. <br>
					<p style="line-height:120%">No remarks.</p>
				</li>
				<li><a href="https://arxiv.org/pdf/1810.12575.pdf">
					"Neural Nearest Neighbors Networks"</a>, NeuralPS 2018. <br>
					<p style="line-height:120%">No remarks.</p>
				</li>    
			</ul>
			
			<!--topic 4-->
			<h3>Lable-Agnostic Group/Clustering</h3>
			<ul class="news-item">
				<li><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Kong_Recurrent_Pixel_Embedding_CVPR_2018_paper.pdf">
					"Recurrent Pixel Embedding for Instance Grouping"</a>, CVPR 2018. <br>
					<p style="line-height:120%">No remarks.</p>
				</li>
				<li><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhan_Online_Deep_Clustering_for_Unsupervised_Representation_Learning_CVPR_2020_paper.pdf">
					"Online Deep Clustering for Unsupervised Representation Learning"</a>, CVPR 2020. <br>
					<p style="line-height:120%">No remarks.</p>
				</li>
				<li><a href="https://arxiv.org/pdf/1807.10007.pdf">
					"Instance Segmentation by Deep Coloring"</a>, arxiv preprint 2018. <br>
					<p style="line-height:120%">No remarks.</p>
				</li>
				<li><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Gao_SSAP_Single-Shot_Instance_Segmentation_With_Affinity_Pyramid_ICCV_2019_paper.pdf">
					"SSAP: Single-Shot Instance Segmentation With Affinity Pyramid"</a>, ICCV 2019. <br>
					<p style="line-height:120%">No remarks.</p>
				</li>
				<li><a href="https://github.com/BGU-CS-VIL/DeepDPM">
					"DeepDPM: Deep Clustering With an Unknown Number of Clusters"</a>, CVPR 2022. <br>
					<p style="line-height:120%">No remarks.</p>		
				</li>
			
			</ul>
			
			<!--topic 5-->
			<h3>Fine Details Recovery</h3>
			<ul class="news-item">
				<li><a href="https://arxiv.org/pdf/2006.10739v1.pdf">
					"Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains"</a>, Arxiv 2020. <br>
					<p style="line-height:120%">No remarks.</p>
				</li>
			
			</ul>
			
			<!--topic 6-->
			<h3>Others</h3>
			<ul class="news-item">
				<li><a href="https://arxiv.org/pdf/2206.07798.pdf">
					"Gaussian Blue Noise"</a>, SIGGRAPH Asia 2022. <br>
					<p style="line-height:120%">An high-quality point sampling approach with blue-noise property. Adaptive sampling based on a density map is supported (e.g. stippling application).</p>
				</li>
				<li><a href="https://arxiv.org/pdf/2201.12220.pdf">
					"Neural Optimal Transport"</a>, ICLR 2023. <br>
					<p style="line-height:120%">Computing optimal transport (OT) maps and plans for strong and weak transport costs in high dimensions with neural networks.
					<a href="https://github.com/iamalexkorotin/NeuralOptimalTransport">[Github]</a></p>
				</li>
			
			</ul>
		</div>



		<br><br><br>
		<!--section 3 ======================================================================= -->
		<h1><font face="Comic sans MS"><b>Nice Websites</b>
		</font></h1><hr>
		<div id="toolweb" class="section" style= "overflow-y:scroll;height:600px;">
			<!-- topic 1 -->
			<h3>Nice Tools</h3>
			<ul class="news-item">
				<li>
				<b>ICON search engine</b>: <a href="https://www.flaticon.com/icons">https://www.flaticon.com/icons</a>
				</li>
				<li>
				<b>Free music for creators</b>: <a href="https://uppbeat.io/">https://uppbeat.io/</a>
				</li>
				<li>
				<b>Sketching hand-drawn like diagrams</b>: <a href="https://excalidraw.com/">https://excalidraw.com/</a>
				</li>
				<li>
				<b>Color scheme grouped by theme</b>: <a href="http://tool.c7sky.com/webcolor/">http://tool.c7sky.com/webcolor/</a>
				</li>
				<li>
				<b>Degraded photo restoration</b>: <a href="https://huggingface.co/spaces/sczhou/CodeFormer">HuggingFace</a>
				</li>
				<li>
				<b>Portrait matting</b>: <a href="https://sight-x.cn/portrait_matting/">https://sight-x.cn/portrait_matting/</a>
				</li>
			</ul>
			
			<!-- topic 2 -->
			<h3>Liked Blogs</h3>
			<ul class="news-item">
				<li type="spics">
					<a href="https://medium.com/@black_51980/novelty-in-science-8f1fd1a0a143">
					Novelty in Science: A guide to reviewers</a>
				</li>
				<li type="spics">
					<a href="https://kvfrans.com/variational-autoencoders-explained/">
					Variational Autoencoders Explained</a>
				</li>
				<li type="spics">
					<a href="https://agustinus.kristia.de/techblog/2016/12/10/variational-autoencoder/">
					Variational Autoencoder: Intuition and Implementation</a>
				</li>
				<li type="spics">
					<a href="https://towardsdatascience.com/attention-is-all-you-need-discovering-the-transformer-paper-73e5ff5e0634">
					Amazing Transformer Intro</a>
				</li>
				<li type="spics">
					<a href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/">
					Transformer: Positional Encoding</a>
				</li>
				<li type="spics">
					<a href="https://towardsdatascience.com/what-is-gumbel-softmax-7f6d9cdcb90e">
					What is Gumbel-Softmax</a>
				</li>
				<li type="spics">
					<a href="https://lilianweng.github.io/lil-log/archive.html">
					Blog homepage: LiL'Log</a>
				</li>
			</ul>
		</div>

	</div>
</div>
</body>
</html>
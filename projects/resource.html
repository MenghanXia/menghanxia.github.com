<!DOCTYPE html>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>ResourcePage</title>
	<link rel="shortcut icon" href="resource/tool_icon.ico" />
    <!-- Bootstrap Core CSS -->
    <link href="resource/bootstrap.min.css" rel="stylesheet">
	<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <!-- Custom CSS -->
    <style>
    body {
        padding-top: 0px;
		background-image: url("./resource/background.jpg");
		background-attachment: fixed;
    }
    </style>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>

<body>
    <!-- Navigation -->
    <!-- Page Content -->
<!-- =========================================== Content Range =========================================== -->
<div class="container" style="background-color:rgba(204,232,207,0.8)">
	
<div id="home" class="col-lg-12 text-center">
    <span style="font-size:36px"><a href="https://menghanxia.github.io/"><img src="./resource/share.gif" width="100"></a>&nbsp;<font face="Comic sans MS">Resource Reference</font></span>
    <br><br>
</div>

<table width="1000" background-color: #D6EEEE>
<tr>
<td align="left"><img src="./resource/sound.png" width="20">&nbsp;&nbsp;<a /href="https://www.youtube.com/watch?v=NqfAhDgawAQ"><font size="4" color="yellow">Relaxing Sound</font></a></td>
<td align="right"><font size="4" color="red">&#x2764 Visitor No.: <span id="busuanzi_value_site_uv"></span>&nbsp;&nbsp;Total view:<span id="busuanzi_value_site_pv"></span></font></td>
</tr>
</table>
<br>

<font face="Comic sans MS" size="5.2" color="rgb(255, 255, 255)">
<table style="width:100%;text-align:center;table-layout:fixed;">
<tr>
<td style="background-color:gold"><a href="#dataset" name="#tab1">Open-source Dataset</a></td>
<td style="background-color:LightPink"><a href="#technic" name="#tab2">Useful Technics</a></td>
<td style="background-color:LightGreen"><a href="#toolweb" name="#tab3">Nice Websites</a></td>
<td style="background-color:LightBlue"><a href="#link" name="#tab4">Linked Blogs</a></td>
</td>
</table>
</font>
<br>


<!--section 1-->
<div id="dataset" class="section">
<h3><font color="rgb(0, 153, 0)">&#10047 <b>Open-source Dataset</b>
<a href="#home">&#8679</a>
</font></h3>
<hr>
<!--topic 1-->
<h4 style="line-height:150%;text-align:left padding-bottom: 20px;border-top-width: 20px;padding-top: 0px;padding-bottom: 20px;">
<li type="square">
<b>Single Images</b>
</li>
    <ol>
        <li><a href="https://r0k.us/graphics/kodak/">Kodak Lossless True Color Image Suite</a> <br>
            <p style="line-height:120%">A classic lossless 24-bits per pixel image dataset, which is commonly used in image processing researches.</p>
        </li>
        <li><a href="http://hdrplusdata.org/dataset.html">HDR+ Burst Photography Dataset</a> <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
        <li>History black & white images: <a href="https://www.boredpanda.com/historic-pictures-colorized/?utm_source=google&utm_medium=organic&utm_campaign=organic">Part I</a>, <a href="https://www.boredpanda.com/colorized-history-black-and-white-pictures-restored-in-color/?utm_source=google&utm_medium=organic&utm_campaign=organic">Part II</a>, <a href="https://www.boredpanda.com/colorized-historic-monochrome-photos/?utm_source=google&utm_medium=organic&utm_campaign=organic">Part III</a> <br>
            <p style="line-height:120%">Old black & white photos and their colorized variants by artists.</p>
        </li>
		<li><a href="https://r0k.us/graphics/kodak/">TELEDYNE FLIR Thermal Dataset</a> <br>
			<p style="line-height:120%">9,711 thermal and 9,233 RGB training/validation images with a suggested training/validation split. Besides, bounding box annotations across 15 different object categories are available.
		</li>
    </ol>

<!--topic 2-->
<li type="square">
<b>Stereo Images</b>
</li>
    <ol>
        <li><a href="https://yingqianwang.github.io/Flickr1024/">Flickr1024: A Large-Scale Dataset for Stereo Image Super-Resolution</a> <br>
            <p style="line-height:120%">1024 high-quality image pairs and covers diverse senarios.</p>
        </li>
        <li><a href="https://keystonedepth.cs.washington.edu/download">KeystoneDepth</a> <br>
            <p style="line-height:120%">A collection of 37,239 rectified historical stereo black & white image pairs from the Keystone-Mast Collection.</p>
        </li>
    
    </ol>
 
<!--topic 3-->
<li type="square">
<b>Light Fields</b>
</li>
    <ol>
        <li><a href="http://lightfields.stanford.edu/LF2016.html">Stanford Lytro Light Field Archive</a> <br>
            <p style="line-height:120%">A dataset captured by the Lytro Illum camera, which are organized into various categories.</p>
        </li>
        <li><a href="http://lightfield.stanford.edu/lfs.html">The (New) Stanford Light Field Archive</a> <br>
            <p style="line-height:120%">Several classic large-baseline light fields, captured by gantry.</p>
        </li>
        <li><a href="https://cseweb.ucsd.edu//~viscomp/projects/LF/papers/SIGASIA16/">A dataset provided by Kalantari et. al.</a> <br>
            <p style="line-height:120%">The training set contains 72 light fields while the testing set contains 30 light fields, which have some overlap with the <i>Stanford Lytro Light Field Archives</i>.</p>
        </li>
        <li><a href="https://hazirbas.com/datasets/ddff12scene/">DDFF 12-Scene Benchmark</a> <br>
            <p style="line-height:120%">DDFF 12-Scene dataset consists of 720 lightfield images and coregistered depth maps.</p>
        </li>
        <li><a href="https://www.irisa.fr/temics/demos/lightField/LowRank2/datasets/datasets.html">INRIA Light Field Dataset</a> <br>
            <p style="line-height:120%">63 light field captured by Lytro first generation camera, and 46 light fields captured by Lytro Illum camera.</p>
        </li>
        <li><a href="https://github.com/lightfield-analysis/resources">Light Field Resources</a> <br>
            <p style="line-height:120%">A repo for collecting links to data sets, source code, and other resources related to research on light fields for computer vision.</p>
        </li>
		
    </ol>
 
<!--topic 4-->
<li type="square">
<b>Talking Head Videos</b>
</li>
    <ol>
        <li><a href="https://celebv-hq.github.io/">CelebV-HQ</a> <br>
            <p style="line-height:120%">CelebV-HQ contains 35,666 video clips involving 15,653 identities and 83 manually labeled facial attributes covering appearance, action, and emotion.</p>
        </li>
        <li><a href="https://liangbinxie.github.io/projects/vfhq">VFHQ</a> <br>
            <p style="line-height:120%">As a new benchmark for video face super-resolution, VFHQ contains over 16,000 high-fidelity clips of diverse interview scenarios.</p>
        </li>
    
    </ol>
  
<!--topic 5-->
 <li type="square">
<b>Misc</b>
</li>
    <ol>
        <li><a href="https://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm#collect">CVonline: Image Databases</a> <br>
            <p style="line-height:120%">A collated list of image and video databases that people have found useful for computer vision research.</p>
        </li>
    
    </ol>
</h4>
</div>


<!--section 2-->
<div id="technic" class="section">
<h3><font color="rgb(0, 153, 0)">&#9752 <b>Useful Technics</b>
<a href="#home">&#8679</a>
</font></h3>
<hr>
<!--topic 1-->
<h4 style="line-height:150%;text-align:left padding-bottom: 20px;border-top-width: 20px;padding-top: 0px;padding-bottom: 20px;">
<li type="square">
<b>Differentiable Quantization</b>
</li>
    <ol>
        <li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9010945">
	        "Differentiable Soft Quantization:Bridging Full-Precision and Low-Bit Neural Networks"</a>, ICCV 2019. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
        <li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8578437">
	        "Learning Convolutional Networks for Content-weighted Image Compression"</a>, CVPR 2018. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
        <li><a href="https://machine-learning-and-security.github.io/papers/mlsec17_paper_54.pdf">
	        "JPEG-resistant Adversarial Images"</a>, NIPS Workshops 2017. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
        <li><a href="https://eccv2018.org/openaccess/content_ECCV_2018/papers/Jiren_Zhu_HiDDeN_Hiding_Data_ECCV_2018_paper.pdf">
	        "HiDDeN: Hiding Data With Deep Networks"</a>, ECCV 2018. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
    
    </ol>

<!--topic 2-->
<li type="square">
<b>Differentiable L0 Norm Regularity</b>
</li>
    <ol>
        <li><a href="https://openreview.net/pdf?id=H1Y8hhg0b">
	        "Learning Sparse Neural Networks through L0 Regularization"</a>, ICLR 2018. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
        <li><a href="http://www.stats.ox.ac.uk/~cmaddis/pubs/concrete.pdf">
	        "The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables"</a>, ICLR 2017. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
    
    </ol>
 
<!--topic 3-->
<li type="square">
<b>Soft Argmax</b>
</li>
    <ol>
        <li><a href="https://link.springer.com/content/pdf/10.1007/s10791-009-9110-3.pdf">
	        "Gradient descent optimization of smoothed information retrieval metrics"</a>, Information Retrieval 2010. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
        <li><a href="https://arxiv.org/pdf/1810.12575.pdf">
	        "Neural Nearest Neighbors Networks"</a>, NeuralPS 2018. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>    
    </ol>
 
<!--topic 4-->
<li type="square">
<b>Lable-Agnostic Group/Clustering</b>
</li>
    <ol>
        <li><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Kong_Recurrent_Pixel_Embedding_CVPR_2018_paper.pdf">
	        "Recurrent Pixel Embedding for Instance Grouping"</a>, CVPR 2018. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
        <li><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhan_Online_Deep_Clustering_for_Unsupervised_Representation_Learning_CVPR_2020_paper.pdf">
	        "Online Deep Clustering for Unsupervised Representation Learning"</a>, CVPR 2020. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
        <li><a href="https://arxiv.org/pdf/1807.10007.pdf">
	        "Instance Segmentation by Deep Coloring"</a>, arxiv preprint 2018. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
        <li><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Gao_SSAP_Single-Shot_Instance_Segmentation_With_Affinity_Pyramid_ICCV_2019_paper.pdf">
	        "SSAP: Single-Shot Instance Segmentation With Affinity Pyramid"</a>, ICCV 2019. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
		<li><a href="https://github.com/BGU-CS-VIL/DeepDPM">
	        "DeepDPM: Deep Clustering With an Unknown Number of Clusters"</a>, CVPR 2022. <br>
            <p style="line-height:120%">No remarks.</p>		
		</li>
    
    </ol>
  
<!--topic 5-->
 <li type="square">
<b>Fine Details Recovery</b>
</li>
    <ol>
        <li><a href="https://arxiv.org/pdf/2006.10739v1.pdf">
	        "Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains"</a>, Arxiv 2020. <br>
            <p style="line-height:120%">No remarks.</p>
        </li>
    
    </ol>
</h4>
</div>


<!--section 3-->
<div id="toolweb" class="section">
<h3><font color="rgb(0, 153, 0)">&#10086 <b>Nice Websites</b>
<a href="#home">&#8679</a>
</font></h3>
<hr>
<h4 style="line-height:150%;text-align:left padding-bottom: 20px;border-top-width: 20px;padding-top: 0px;padding-bottom: 20px;">
<li type="square">
<b>ICON search engine</b>: <a href="https://www.flaticon.com/icons">https://www.flaticon.com/icons</a>
</li>
<li type="square">
<b>Free music for creators</b>: <a href="https://uppbeat.io/">https://uppbeat.io/</a>
</li>

</h4>
</div>


<!--section 4-->
<div id="link" class="section">
<h3><font color="rgb(0, 153, 0)">&#9992 <b>Liked Blogs</b>
<a href="#home">&#8679</a>
</font></h3>
<hr style="line-height:10px">
<!--topic 1-->
<h4 style="line-height:150%;text-align:left padding-bottom: 20px;border-top-width: 20px;padding-top: 0px;padding-bottom: 20px;">
<ul>
<li type="spics">
    <a href="https://medium.com/@black_51980/novelty-in-science-8f1fd1a0a143">
    Novelty in Science: A guide to reviewers</a>
</li>
<li type="spics">
    <a href="https://kvfrans.com/variational-autoencoders-explained/">
    Variational Autoencoders Explained</a>
</li>
<li type="spics">
    <a href="https://agustinus.kristia.de/techblog/2016/12/10/variational-autoencoder/">
    Variational Autoencoder: Intuition and Implementation</a>
</li>
<li type="spics">
    <a href="https://towardsdatascience.com/attention-is-all-you-need-discovering-the-transformer-paper-73e5ff5e0634">
    Amazing Transformer Intro</a>
</li>
<li type="spics">
    <a href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/">
    Transformer: Positional Encoding</a>
</li>
<li type="spics">
    <a href="https://towardsdatascience.com/what-is-gumbel-softmax-7f6d9cdcb90e">
    What is Gumbel-Softmax</a>
</li>
<li type="spics">
    <a href="https://lilianweng.github.io/lil-log/archive.html">
    Blog homepage: LiL'Log</a>
</li>

</ul>
</h4>
</div>

</div>
</body>
</html>
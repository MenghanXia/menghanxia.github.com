<!DOCTYPE html>
<!-- saved from url=(0046)https://shangchenzhou.com/projects/CodeFormer/ -->
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->
  <title>DISCO</title>
  <link rel="shortcut icon" href="./disco/favicon.ico">
  <link rel="stylesheet" href="./disco/project.css">
  <link rel="stylesheet" href="./disco/bootstrap.min.css">
</head>
<body>
  <div id="content" style="line-height:150%;text-align:left padding-bottom: 20px;border-top-width: 20px;padding-top: 0px;padding-bottom: 20px;">
    <div class="head" style="background-color:rgba(255,255,255,0.95)">
      <h1>
        DISCO: <font color="Tomato">Dis</font>entangled Image <font color="Tomato">Co</font>lorization via Global Anchors
      </h1>
      <!--=================Authors==========================-->
      <div class="authors">
        <a href="https://menghanxia.github.io/" target="_blank">Menghan Xia<sup>1</sup></a> 
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://wbhu.github.io/" target="_blank">Wenbo Hu<sup>2</sup></a> 
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="http://www.cse.cuhk.edu.hk/~ttwong/" target="_blank">Tien-Tsin Wong<sup>2</sup></a> 
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://juewang725.github.io/" target="_blank">Jue Wang<sup>1</sup></a>
      </div>
      <div class="affiliations ">Tencent AI Lab<sup>1</sup> &nbsp;&nbsp;&nbsp;&nbsp; The Chinese University of Hong Kong<sup>2</sup></div>
      <div class="venue ">ACM Transactions on Graphics (Special issue of SIGGRAPH Asia 2022)</div>
    </div> <!-- .head -->
	<hr>
		
    <!--=================Materials==========================-->
    <div class="section">
      <div class="row">
        <div class="col-3 text-center">
            <a href="./disco/disco_main.pdf" target="_blank" class="imageLink"><img src="./disco/paper.png" ,="" height="100"></a><br><br>
            <a href="./disco/disco_main.pdf" target="_blank">Paper</a> | <a href="./disco/disco_supp.pdf" target="_blank">Supp</a>
        </div>
        <div class="col-3 text-center">
            <a href="https://1drv.ms/u/s!Al07CQ4AbykHkjItNln63Hh42lWz?e=bwSQDf" target="_blank" class="imageLink"><img src="./disco/icon_dataset.png" ,="" height="100"></a><br>
            Evaluation Results<br>
            (<a href="https://1drv.ms/u/s!Al07CQ4AbykHkjItNln63Hh42lWz?e=bwSQDf" target="_blank">COCO5k</a> | <a href="https://1drv.ms/u/s!Al07CQ4AbykHkjPfOlxKnjFdnRDj?e=77YELC" target="_blank">ImageNet10k</a>)
        </div>
        <div class="col-3 text-center">
            <a href="https://github.com/MenghanXia/DisentangledColorization" target="_blank" class="imageLink"><img src="./disco/icon_github.png" ,="" height="100"></a><br><br>
              <a href="https://github.com/MenghanXia/DisentangledColorization" target="_blank">Codes & Model</a>
        </div>
        <div class="col-3 text-center">
            <a href="https://huggingface.co/spaces/menghanxia/disco" target="_blank" class="imageLink"><img src="./disco/logo.png" ,="" height="100"></a><br><br>
            <a href="https://huggingface.co/spaces/menghanxia/disco" target="_blank">Online Demo</a>
        </div>
      </div> <!-- .row -->
    </div> <!-- .section -->
	
    <div id="teaser" class="section">
	<br>
	<img src="./disco/teaser.jpg">
	</div>
	
    <!--=================Abstract==========================-->
    <div id="abstract" class="section">
      <h2>Abstract</h2>
      <p>Colorization is multimodal by nature and challenges existing frameworks to achieve colorful and structurally consistent results. Even the sophisticated autoregressive model struggles to maintain long-distance color consistency due to the fragility of sequential dependence.
	  To overcome this challenge, <b>we propose a novel colorization framework that disentangles color multimodality and structure consistency through global color anchors, so that both aspects could be learned effectively.</b> Our key insight is that several carefully located anchors could approximately represent the color distribution of an image, and conditioned on the anchor colors, we can predict the image color in a deterministic manner by utilizing internal correlation. To this end, we construct a colorization model with dual branches, where the color modeler predicts the color distribution for anchor color representation, and the color generator predicts the pixel colors by referring the sampled anchor colors. Importantly, the anchors are located under two principles: color independence and global coverage, which is realized with clustering analysis on the deep color features. To simplify the computation, we creatively adopt soft superpixel segmentation to reduce the image primitives, which still nicely reserves the reversibility to pixel-wise representation.
      Extensive experiments show that our method achieves notable superiority over various mainstream frameworks in perceptual quality. Thanks to anchor-based color representation, our model has the flexibility to support diverse and controllable colorization as well.</p>
    </div> <!-- .section -->

    <!--=================Method==========================-->
    <div id="method" class="section">
      <h2>Method</h2>
      <p>
      Given a grayscale input G, we extract the feature map F and the local affinity association map A at feature extraction stage. Then, the tokenized backbone feature F′ is used for anchor-based color modeling and anchor-guided color generation respectively. Particularly, the anchors are adaptively located by the anchor locator. At last, by pixel-level refinement, we obtain the color output C. ⊙ denotes Hadamard product and ⊕ denotes concatenation along the channel axis.</p>
      <img src="./disco/network.png">
      <h5 class="text-center">Model overview</h5>
    </div> <!-- .section -->
    

    <div id="results" class="section">
      <h2>Results</h2>
	  <p>Comparing to natural scenes that usually have little color ambiguity, man-made scenes, such as human clothes, vehicles, sport facilities, and daily articles, may present diverse colors potentially and thus are more challenging to colorization algorithms. Here we mainly illustrate results on such scenes in comparison with <b>existing colorization methods</b>:<a href="https://github.com/richzhang/colorization" target="_blank">CIColor</a>, <a href="https://github.com/pvitoria/ChromaGAN" target="_blank">ChromaGAN</a>, <a href="https://github.com/richzhang/colorization" target="_blank">UGColor</a>, <a href="https://github.com/ericsujw/InstColorization" target="_blank">InstColor</a>, <a href="https://github.com/jantic/DeOldify" target="_blank">Deoldify</a>, <a href="https://github.com/google-research/google-research/tree/master/coltran" target="_blank">ColTran</a>, for which we use their official implementation and pretrained models for comparison.</p>

	  <p>For inference, the input grayscale image is first resized to 256x256 before fed to the model and the output chromatic channels are bilinearly rescaled to the orginal resolution, which together makes the colorized RGB image. Below illustrates a subset of our comparative cases.
	  </p>
	  <br>
	  <table width="100%" cellspacing="1" align="center">
	  <tr font face="DFKai-sb">
	  <td align=center width="13%">Input</td>
	  <td align=center width="13%">UGColor</td>
	  <td align=center width="13%">InstColor</td>
	  <td align=center width="13%">Deoldify</td>
	  <td align=center width="13%">ColTran</td>
	  <td align=center width="13%"><b>Ours</b></td>
	  <td align=center width="15%">Ground truth</td>
	  </tr>
	  </table>
	  <div style= "overflow-y:scroll;height:500px;">
      <img src="./disco/showcase.jpg">
	  </div>
    </div> <!-- .section -->
	 

    <!--=================Citation==========================-->
    <div id="material" class="section">
      <h2>Materials</h2>
	  <P><b>Full set of case comparison</b>: <a href="https://drive.google.com/file/d/1aadVJ1sjIqUTZYJymu3TLQ5AfYBFUHCD/view?usp=sharing" target="_blank">GoogleDrive</a> | <a href="https://1drv.ms/u/s!Al07CQ4AbykHkjFmNK9AxBqF046z?e=owZP2n" target="_blank">OneDrive</a></P>
	  <P><b>Our results on dataset</b>: <a href="https://1drv.ms/u/s!Al07CQ4AbykHkjItNln63Hh42lWz?e=bwSQDf" target="_blank">COCO5k</a> | <a href="https://1drv.ms/u/s!Al07CQ4AbykHkjPfOlxKnjFdnRDj?e=77YELC" target="_blank">ImageNet10k</a> </P>
      <p><b>Evaluation metrics</b>: <a href="https://drive.google.com/file/d/18SXfoz4y47ufggA8qt92ref5tZ7KJzqe/view?usp=sharing" target="_blank">Python Implementation</a></p>
    </div> <!-- .section -->
	

    <!--=================Citation==========================-->
    <div id="citation" class="section">
      <h2>Citation</h2>
      <p>If you find our dataset and paper useful for your research, please consider citing our work:</p>
      <pre>@article{XiaHWW22,
		author   = {Menghan Xia and Wenbo Hu and Tien-Tsin Wong and Jue Wang},
		title    = {Disentangled Image Colorization via Global Anchors},
		journal  = {ACM Transactions on Graphics (TOG)},
		volume   = {41},
		number   = {6},
		pages    = {204:1--204:13},
		year = {2022}
	  }</pre>
    </div> <!-- .section -->
	
</div>
</body></html>